{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import _pickle as cPickle\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import random\n",
    "\n",
    "project_dir = \"./\"\n",
    "data_dir = \"../Data/\"\n",
    "\n",
    "# (NOTE! this is taken from the official Cityscapes scripts:)\n",
    "Label = namedtuple( 'Label' , [\n",
    "\n",
    "    'name'        , # The identifier of this label, e.g. 'car', 'person', ... .\n",
    "                    # We use them to uniquely name a class\n",
    "\n",
    "    'id'          , # An integer ID that is associated with this label.\n",
    "                    # The IDs are used to represent the label in ground truth images\n",
    "                    # An ID of -1 means that this label does not have an ID and thus\n",
    "                    # is ignored when creating ground truth images (e.g. license plate).\n",
    "                    # Do not modify these IDs, since exactly these IDs are expected by the\n",
    "                    # evaluation server.\n",
    "\n",
    "    'trainId'     , # Feel free to modify these IDs as suitable for your method. Then create\n",
    "                    # ground truth images with train IDs, using the tools provided in the\n",
    "                    # 'preparation' folder. However, make sure to validate or submit results\n",
    "                    # to our evaluation server using the regular IDs above!\n",
    "                    # For trainIds, multiple labels might have the same ID. Then, these labels\n",
    "                    # are mapped to the same class in the ground truth images. For the inverse\n",
    "                    # mapping, we use the label that is defined first in the list below.\n",
    "                    # For example, mapping all void-type classes to the same ID in training,\n",
    "                    # might make sense for some approaches.\n",
    "                    # Max value is 255!\n",
    "\n",
    "    'category'    , # The name of the category that this label belongs to\n",
    "\n",
    "    'categoryId'  , # The ID of this category. Used to create ground truth images\n",
    "                    # on category level.\n",
    "\n",
    "    'hasInstances', # Whether this label distinguishes between single instances or not\n",
    "\n",
    "    'ignoreInEval', # Whether pixels having this class as ground truth label are ignored\n",
    "                    # during evaluations or not\n",
    "\n",
    "    'color'       , # The color of this label\n",
    "    ] )\n",
    "\n",
    "# (NOTE! this is taken from the official Cityscapes scripts:)\n",
    "labels = [\n",
    "    #       name                     id    trainId   category            catId     hasInstances   ignoreInEval   color\n",
    "    Label(  'unlabeled'            ,  0 ,      19 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'ego vehicle'          ,  1 ,      19 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'rectification border' ,  2 ,      19 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'out of roi'           ,  3 ,      19 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'static'               ,  4 ,      19 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'dynamic'              ,  5 ,      19 , 'void'            , 0       , False        , True         , (111, 74,  0) ),\n",
    "    Label(  'ground'               ,  6 ,      19 , 'void'            , 0       , False        , True         , ( 81,  0, 81) ),\n",
    "    Label(  'road'                 ,  7 ,        0 , 'flat'            , 1       , False        , False        , (128, 64,128) ),\n",
    "    Label(  'sidewalk'             ,  8 ,        1 , 'flat'            , 1       , False        , False        , (244, 35,232) ),\n",
    "    Label(  'parking'              ,  9 ,      19 , 'flat'            , 1       , False        , True         , (250,170,160) ),\n",
    "    Label(  'rail track'           , 10 ,      19 , 'flat'            , 1       , False        , True         , (230,150,140) ),\n",
    "    Label(  'building'             , 11 ,        2 , 'construction'    , 2       , False        , False        , ( 70, 70, 70) ),\n",
    "    Label(  'wall'                 , 12 ,        3 , 'construction'    , 2       , False        , False        , (102,102,156) ),\n",
    "    Label(  'fence'                , 13 ,        4 , 'construction'    , 2       , False        , False        , (190,153,153) ),\n",
    "    Label(  'guard rail'           , 14 ,      19 , 'construction'    , 2       , False        , True         , (180,165,180) ),\n",
    "    Label(  'bridge'               , 15 ,      19 , 'construction'    , 2       , False        , True         , (150,100,100) ),\n",
    "    Label(  'tunnel'               , 16 ,      19 , 'construction'    , 2       , False        , True         , (150,120, 90) ),\n",
    "    Label(  'pole'                 , 17 ,        5 , 'object'          , 3       , False        , False        , (153,153,153) ),\n",
    "    Label(  'polegroup'            , 18 ,      19 , 'object'          , 3       , False        , True         , (153,153,153) ),\n",
    "    Label(  'traffic light'        , 19 ,        6 , 'object'          , 3       , False        , False        , (250,170, 30) ),\n",
    "    Label(  'traffic sign'         , 20 ,        7 , 'object'          , 3       , False        , False        , (220,220,  0) ),\n",
    "    Label(  'vegetation'           , 21 ,        8 , 'nature'          , 4       , False        , False        , (107,142, 35) ),\n",
    "    Label(  'terrain'              , 22 ,        9 , 'nature'          , 4       , False        , False        , (152,251,152) ),\n",
    "    Label(  'sky'                  , 23 ,       10 , 'sky'             , 5       , False        , False        , ( 70,130,180) ),\n",
    "    Label(  'person'               , 24 ,       11 , 'human'           , 6       , True         , False        , (220, 20, 60) ),\n",
    "    Label(  'rider'                , 25 ,       12 , 'human'           , 6       , True         , False        , (255,  0,  0) ),\n",
    "    Label(  'car'                  , 26 ,       13 , 'vehicle'         , 7       , True         , False        , (  0,  0,142) ),\n",
    "    Label(  'truck'                , 27 ,       14 , 'vehicle'         , 7       , True         , False        , (  0,  0, 70) ),\n",
    "    Label(  'bus'                  , 28 ,       15 , 'vehicle'         , 7       , True         , False        , (  0, 60,100) ),\n",
    "    Label(  'caravan'              , 29 ,      19 , 'vehicle'         , 7       , True         , True         , (  0,  0, 90) ),\n",
    "    Label(  'trailer'              , 30 ,      19 , 'vehicle'         , 7       , True         , True         , (  0,  0,110) ),\n",
    "    Label(  'train'                , 31 ,       16 , 'vehicle'         , 7       , True         , False        , (  0, 80,100) ),\n",
    "    Label(  'motorcycle'           , 32 ,       17 , 'vehicle'         , 7       , True         , False        , (  0,  0,230) ),\n",
    "    Label(  'bicycle'              , 33 ,       18 , 'vehicle'         , 7       , True         , False        , (119, 11, 32) ),\n",
    "    Label(  'license plate'        , -1 ,       -1 , 'vehicle'         , 7       , False        , True         , (  0,  0,142) ),\n",
    "]\n",
    "\n",
    "# create a function mapping id to trainId:\n",
    "id_to_trainId = {label.id: label.trainId for label in labels}\n",
    "id_to_trainId_map_func = np.vectorize(id_to_trainId.get)\n",
    "\n",
    "new_img_height = 256 # (the height all images fed to the model will be resized to)\n",
    "new_img_width = 256 # (the width all images fed to the model will be resized to)\n",
    "no_of_classes = 20 # (number of object classes (road, sidewalk, car etc.))\n",
    "\n",
    "cityscapes_dir = data_dir + \"CityScapes/\"\n",
    "\n",
    "train_imgs_dir = cityscapes_dir + \"leftImg8bit_trainvaltest/leftImg8bit/train/\"\n",
    "train_gt_dir = cityscapes_dir + \"gtFine_trainvaltest/gtFine/train/\"\n",
    "\n",
    "val_imgs_dir = cityscapes_dir + \"leftImg8bit_trainvaltest/leftImg8bit/val/\"\n",
    "val_gt_dir = cityscapes_dir + \"gtFine_trainvaltest/gtFine/val/\"\n",
    "\n",
    "train_dirs = [\"jena/\", \"zurich/\", \"weimar/\", \"ulm/\", \"tubingen/\", \"stuttgart/\",\n",
    "            \"strasbourg/\", \"monchengladbach/\", \"krefeld/\", \"hanover/\",\n",
    "            \"hamburg/\", \"erfurt/\", \"dusseldorf/\", \"darmstadt/\", \"cologne/\",\n",
    "            \"bremen/\", \"bochum/\", \"aachen/\"]\n",
    "val_dirs = [\"frankfurt/\", \"munster/\", \"lindau/\"]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "img = cv2.imread(\"/home/abraham/Projects/ML/data/train_masks/aachen_000000_000019_trainId_label.png\",-1)\n",
    "img = to_categorical(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path to all training images and their corresponding label image:\n",
    "train_img_paths = []\n",
    "train_trainId_label_paths = []\n",
    "for dir_step, dir in enumerate(train_dirs):\n",
    "    img_dir = train_imgs_dir + dir\n",
    "\n",
    "    file_names = os.listdir(img_dir)\n",
    "    for step, file_name in enumerate(file_names):\n",
    "#         if step % 10 == 0:\n",
    "#             print(\"train dir %d/%d, step %d/%d\" % (dir_step, len(train_dirs)-1,\n",
    "#                         step, len(file_names)-1))\n",
    "\n",
    "        img_id = file_name.split(\"_left\")[0]\n",
    "\n",
    "        # read the image:\n",
    "        img_path = img_dir + file_name\n",
    "        img = cv2.imread(img_path, -1)\n",
    "\n",
    "        # resize the image without interpolation (want the image to still match\n",
    "        # the corresponding label image which we reisize below) and save to\n",
    "        # project_dir/data:\n",
    "        img_small = cv2.resize(img, (new_img_width, new_img_height),\n",
    "                    interpolation=cv2.INTER_NEAREST)\n",
    "        img_small_path = project_dir + \"data/train_frames/\" + img_id + \".png\"\n",
    "        cv2.imwrite(img_small_path, img_small)\n",
    "        train_img_paths.append(img_small_path)\n",
    "\n",
    "        # read and resize the corresponding label image without interpolation\n",
    "        # (want the resulting image to still only contain pixel values\n",
    "        # corresponding to an object class):\n",
    "        gt_img_path = train_gt_dir + dir + img_id + \"_gtFine_labelIds.png\"\n",
    "        gt_img = cv2.imread(gt_img_path, -1)\n",
    "        gt_img_small = cv2.resize(gt_img, (new_img_width, new_img_height),\n",
    "                        interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # convert the label image from id to trainId pixel values:\n",
    "        id_label = gt_img_small\n",
    "        trainId_label = id_to_trainId_map_func(id_label)\n",
    "\n",
    "        # save the label image to project_dir/data:\n",
    "        trainId_label_path = project_dir + \"data/train_masks/\" + img_id + \"_trainId_label.png\"\n",
    "        cv2.imwrite(trainId_label_path, trainId_label)\n",
    "        train_trainId_label_paths.append(trainId_label_path)\n",
    "        \n",
    "    print(\"train dir %d/%d, step %d/%d\" % (dir_step, len(train_dirs)-1,\n",
    "                        step, len(file_names)-1))\n",
    "        \n",
    "# cPickle.dump(train_img_paths,\n",
    "#             open(project_dir + \"data/train_img_paths.pkl\", \"w\"))\n",
    "# cPickle.dump(train_trainId_label_paths,\n",
    "#             open(project_dir + \"data/train_trainId_label_paths.pkl\", \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean color channels of the train imgs:\n",
    "print(\"computing mean color channels of the train imgs\")\n",
    "no_of_train_imgs = len(train_img_paths)\n",
    "mean_channels = np.zeros((3, ))\n",
    "for step, img_path in enumerate(train_img_paths):\n",
    "    if step % 100 == 0:\n",
    "        print(step)\n",
    "    img = cv2.imread(img_path, -1)\n",
    "\n",
    "    img_mean_channels = np.mean(img, axis=0)\n",
    "    img_mean_channels = np.mean(img_mean_channels, axis=0)\n",
    "\n",
    "    mean_channels += img_mean_channels\n",
    "\n",
    "mean_channels = mean_channels/float(no_of_train_imgs)\n",
    "\n",
    "# # save to disk:\n",
    "# cPickle.dump(mean_channels, open(project_dir + \"data/mean_channels.pkl\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the class weights:\n",
    "print(\"computing class weights\")\n",
    "trainId_to_count = {}\n",
    "for trainId in range(no_of_classes):\n",
    "    trainId_to_count[trainId] = 0\n",
    "\n",
    "# # get the total number of pixels in all train labels that are of each\n",
    "# # object class:\n",
    "for step, trainId_label_path in enumerate(train_trainId_label_paths):\n",
    "    if step % 100 == 0:\n",
    "        print(step)\n",
    "\n",
    "    # read the label image:\n",
    "    trainId_label = cv2.imread(trainId_label_path, -1)\n",
    "\n",
    "    for trainId in range(no_of_classes):\n",
    "        # count how many pixels in the label image are of object class trainId:\n",
    "        trainId_mask = np.equal(trainId_label, trainId)\n",
    "        label_trainId_count = np.sum(trainId_mask)\n",
    "\n",
    "        # add to the total count:\n",
    "        trainId_to_count[trainId] += label_trainId_count\n",
    "\n",
    "# # compute the class weights according to the paper:\n",
    "class_weights = []\n",
    "total_count = sum(trainId_to_count.values())\n",
    "for trainId, count in trainId_to_count.items():\n",
    "    trainId_prob = float(count)/float(total_count)\n",
    "    trainId_weight = 1/np.log(1.02 + trainId_prob)\n",
    "    class_weights.append(trainId_weight)\n",
    "\n",
    "# # save to disk:\n",
    "# cPickle.dump(class_weights, open(project_dir + \"data/class_weights.pkl\", \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path to all validation images and their corresponding label image:\n",
    "val_img_paths = []\n",
    "val_trainId_label_paths = []\n",
    "for dir_step, dir in enumerate(val_dirs):\n",
    "    img_dir = val_imgs_dir + dir\n",
    "\n",
    "    file_names = os.listdir(img_dir)\n",
    "    for step, file_name in enumerate(file_names):\n",
    "#         if step % 10 == 0:\n",
    "#             print(\"val dir %d/%d, step %d/%d\" % (dir_step, len(val_dirs)-1,\n",
    "#                         step, len(file_names)-1))\n",
    "\n",
    "        img_id = file_name.split(\"_left\")[0]\n",
    "\n",
    "        # read the image:\n",
    "        img_path = img_dir + file_name\n",
    "        img = cv2.imread(img_path, -1)\n",
    "\n",
    "        # resize the image without interpolation (want the image to still match\n",
    "        # the corresponding label image which we reisize below) and save to\n",
    "        # project_dir/data:\n",
    "        img_small = cv2.resize(img, (new_img_width, new_img_height),\n",
    "                    interpolation=cv2.INTER_NEAREST)\n",
    "        img_small_path = project_dir + \"data/val_frames/\" + img_id + \".png\"\n",
    "        cv2.imwrite(img_small_path, img_small)\n",
    "        val_img_paths.append(img_small_path)\n",
    "\n",
    "        # read and resize the corresponding label image without interpolation\n",
    "        # (want the resulting image to still only contain pixel values\n",
    "        # corresponding to an object class):\n",
    "        gt_img_path = val_gt_dir + dir + img_id + \"_gtFine_labelIds.png\"\n",
    "        gt_img = cv2.imread(gt_img_path, -1)\n",
    "        gt_img_small = cv2.resize(gt_img, (new_img_width, new_img_height),\n",
    "                    interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # convert the label image from id to trainId pixel values:\n",
    "        id_label = gt_img_small\n",
    "        trainId_label = id_to_trainId_map_func(id_label)\n",
    "\n",
    "        # save the label image to project_dir/data:\n",
    "        trainId_label_path = project_dir + \"data/val_masks/\" + img_id + \"_trainId_label.png\"\n",
    "        cv2.imwrite(trainId_label_path, trainId_label)\n",
    "        val_trainId_label_paths.append(trainId_label_path)\n",
    "        \n",
    "    print(\"val dir %d/%d, step %d/%d\" % (dir_step, len(val_dirs)-1,\n",
    "                        step, len(file_names)-1))\n",
    "\n",
    "# # save the validation data to disk:\n",
    "# cPickle.dump(val_trainId_label_paths,\n",
    "#             open(project_dir + \"data/val_trainId_label_paths.pkl\", \"w\"))\n",
    "# cPickle.dump(val_img_paths,\n",
    "#             open(project_dir + \"data/val_img_paths.pkl\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}